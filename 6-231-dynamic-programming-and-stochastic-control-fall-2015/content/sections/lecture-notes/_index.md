---
course_id: 6-231-dynamic-programming-and-stochastic-control-fall-2015
layout: course_section
menu:
  leftnav:
    identifier: 4b7e0c07417b481ba1c311a80d8c2948
    name: Lecture Slides
    weight: 20
title: Lecture Slides
type: course
uid: 4b7e0c07417b481ba1c311a80d8c2948

---

[Complete Lecture Slides (PDF - 2.9MB)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_notes)

| LEC # | TOPICS |
| --- | --- |
| {{< td-colspan 2 >}}**Finite Horizon Problems**{{< /td-colspan >}} ||
| [Lecture 1 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec1) |  {{< br >}}{{< br >}} *   Introduction to Dynamic Programming{{< br >}}*   Examples of Dynamic Programming{{< br >}}*   Significance of Feedback {{< br >}}{{< br >}}  |
| [Lecture 2 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec2) |  {{< br >}}{{< br >}} *   The Basic Problem{{< br >}}*   Principle of Optimality{{< br >}}*   The General Dynamic Programming Algorithm{{< br >}}*   State Augmentation {{< br >}}{{< br >}}  |
| [Lecture 3 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec3) |  {{< br >}}{{< br >}} *   Deterministic Finite-State Problem{{< br >}}*   Backward Shortest Path Algorithm{{< br >}}*   Forward Shortest Path Algorithm{{< br >}}*   Alternative Shortest Path Algorithms {{< br >}}{{< br >}}  |
| [Lecture 4 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec4) |  {{< br >}}{{< br >}} *   Examples of Stochastic Dynamic Programming Problems{{< br >}}*   Linear-Quadratic Problems{{< br >}}*   Inventory Control {{< br >}}{{< br >}}  |
| [Lecture 5 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec5) |  {{< br >}}{{< br >}} *   Stopping Problems{{< br >}}*   Scheduling Problems{{< br >}}*   Minimax Control {{< br >}}{{< br >}}  |
| [Lecture 6 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec6) |  {{< br >}}{{< br >}} *   Problems with Imperfect State Info{{< br >}}*   Reduction to the Perfect State Info Cas{{< br >}}*   Linear Quadratic Problems{{< br >}}*   Separation of Estimation and Control {{< br >}}{{< br >}}  |
| [Lecture 7 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec7) |  {{< br >}}{{< br >}} *   Imperfect State Information{{< br >}}*   Sufficient Statistics{{< br >}}*   Conditional State Distribution as a Sufficient Statistic{{< br >}}*   Finite-State Analysis {{< br >}}{{< br >}}  |
| [Lecture 8 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec8) |  {{< br >}}{{< br >}} *   Suboptimal Control{{< br >}}*   Cost Approximation Methods: Classification{{< br >}}*   Certainty Equivalent Control{{< br >}}*   Limited Lookahead Policies{{< br >}}*   Performance Bounds{{< br >}}*   Problem Approximation Approach{{< br >}}*   Parametric Cost-To-Go Approximation {{< br >}}{{< br >}}  |
| [Lecture 9 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec9) |  {{< br >}}{{< br >}} *   Rollout Algorithms{{< br >}}*   Cost Improvement Property{{< br >}}*   Discrete Deterministic Problems{{< br >}}*   Approximations to Rollout Algorithms{{< br >}}*   Model Predictive Control (MPS){{< br >}}*   Discretization of Continuous Time{{< br >}}*   Discretization of Continuous Space{{< br >}}*   Other Suboptimal Approaches {{< br >}}{{< br >}}  |
| {{< td-colspan 2 >}}**Simple Infinite Horizon Problems**{{< /td-colspan >}} ||
| [Lecture 10 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec10) |  {{< br >}}{{< br >}} *   Infinite Horizon Problems{{< br >}}*   Stochastic Shortest Path (SSP) Problems{{< br >}}*   Bellman's Equation{{< br >}}*   Dynamic Programming – Value Iteration{{< br >}}*   Discounted Problems as a Special Case of SSP {{< br >}}{{< br >}}  |
| [Lecture 11 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec11) |  {{< br >}}{{< br >}} *   Review of Stochastic Shortest Path Problems{{< br >}}*   Computation Methods for SSP{{< br >}}*   Computational Methods for Discounted Problems {{< br >}}{{< br >}}  |
| [Lecture 12 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec12) |  {{< br >}}{{< br >}} *   Average Cost Per Stage Problems{{< br >}}*   Connection With Stochastic Shortest Path Problems{{< br >}}*   Bellman's Equation{{< br >}}*   Value Iteration, Policy Iteration {{< br >}}{{< br >}}  |
| [Lecture 13 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec13) |  {{< br >}}{{< br >}} *   Control of Continuous-Time Markov Chains: Semi-Markov Problems{{< br >}}*   Problem Formulation: Equivalence to Discrete-Time Problems{{< br >}}*   Discounted Problems{{< br >}}*   Average Cost Problems {{< br >}}{{< br >}}  |
| {{< td-colspan 2 >}}**Advanced Infinite Horizon Problems**{{< /td-colspan >}} ||
| [Lecture 14 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec14) |  {{< br >}}{{< br >}} *   Introduction to Advanced Infinite Horizon Dynamic Programming and Approximation Methods {{< br >}}{{< br >}}  |
| [Lecture 15 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec15) |  {{< br >}}{{< br >}} *   Review of Basic Theory of Discounted Problems{{< br >}}*   Monotonicity of Contraction Properties{{< br >}}*   Contraction Mappings in Dynamic Programming{{< br >}}*   Discounted Problems: Countable State Space with Unbounded Costs{{< br >}}*   Generalized Discounted Dynamic Programming{{< br >}}*   An Introduction to Abstract Dynamic Programming {{< br >}}{{< br >}}  |
| [Lecture 16 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec16) |  {{< br >}}{{< br >}} *   Review of Computational Theory of Discounted Problems{{< br >}}*   Value Iteration (VI){{< br >}}*   Policy Iteration (PI){{< br >}}*   Optimistic PI{{< br >}}*   Computational Methods for Generalized Discounted Dynamic Programming{{< br >}}*   Asynchronous Algorithms {{< br >}}{{< br >}}  |
| [Lecture 17 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec17) |  {{< br >}}{{< br >}} *   Undiscounted Problems{{< br >}}*   Stochastic Shortest Path Problems{{< br >}}*   Proper and Improper Policies{{< br >}}*   Analysis and Computational Methods for SSP{{< br >}}*   Pathologies of SSP{{< br >}}*   SSP Under Weak Conditions {{< br >}}{{< br >}}  |
| [Lecture 18 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec18) |  {{< br >}}{{< br >}} *   Undiscounted Total Cost Problems{{< br >}}*   Positive and Negative Cost Problems{{< br >}}*   Deterministic Optimal Cost Problems{{< br >}}*   Adaptive (Linear Quadratic) Dynamic Programming{{< br >}}*   Affine Monotomic and Risk Sensitive Problems {{< br >}}{{< br >}}  |
| [Lecture 19 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec19) |  {{< br >}}{{< br >}} *   Introduction to approximate Dynamic Programming{{< br >}}*   Approximation in Policy Space{{< br >}}*   Approximation in Value Space, Rollout / Simulation-based Single Policy Iteration{{< br >}}*   Approximation in Value Space Using Problem Approximation {{< br >}}{{< br >}}  |
| [Lecture 20 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec20) |  {{< br >}}{{< br >}} *   Discounted Problems{{< br >}}*   Approximate (fitted) VI{{< br >}}*   Approximate PI{{< br >}}*   The Projected Equation{{< br >}}*   Contraction Properties: Error Bounds{{< br >}}*   Matrix Form of the Projected Equation{{< br >}}*   Simulation-based Implementation{{< br >}}*   LSTD, LSPE, and TD Methods {{< br >}}{{< br >}}  |
| [Lecture 21 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec21) |  {{< br >}}{{< br >}} *   Review of Approximate Policy Iteration{{< br >}}*   Projected Equation Methods for Policy Evaluation{{< br >}}*   Simulation-Based Implementation Issues, Multistep Projected Equation Methods{{< br >}}*   Bias-Variance Tradeoff{{< br >}}*   Exploration-Enhanced Implementations, Oscillations {{< br >}}{{< br >}}  |
| [Lecture 22 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec22) |  {{< br >}}{{< br >}} *   Aggregation as an Approximation Methodology{{< br >}}*   Aggregate Problem{{< br >}}*   Simulation-based Aggregation{{< br >}}*   Q-Learning {{< br >}}{{< br >}}  |
| [Lecture 23 (PDF)]({{< baseurl >}}/sections/lecture-notes/mit6_231f15_lec23) |  {{< br >}}{{< br >}} *   Additional Topics in Advanced Dynamic Programming{{< br >}}*   Stochastic Shortest Path Problems{{< br >}}*   Average Cost Problems{{< br >}}*   Generalizations{{< br >}}*   Basis Function Adaptation{{< br >}}*   Gradient-based Approximation in Policy Space{{< br >}}*   An Overview {{< br >}}{{< br >}}