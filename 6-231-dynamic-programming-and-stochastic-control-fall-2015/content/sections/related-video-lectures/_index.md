---
course_id: 6-231-dynamic-programming-and-stochastic-control-fall-2015
layout: course_section
menu:
  leftnav:
    identifier: e0ea528128d8a624388da079ca1ce048
    name: Related Video Lectures
    weight: 60
title: Related Video Lectures
type: course
uid: e0ea528128d8a624388da079ca1ce048

---

**Summer 2014**

These videos and lecture notes are from a 6-lecture, 12-hour short course on Approximate Dynamic Programming, taught by Professor Dimitri P. Bertsekas at Tsinghua University in Beijing, China in June 2014. They focus primarily on the advanced research-oriented issues of large scale infinite horizon dynamic programming, which corresponds to lectures 11-23 of the MIT 6.231 course.

The complete set of lecture notes are available here: [Complete Slides (PDF - 1.6MB)]({{< baseurl >}}/sections/related-video-lectures/mit6_231f15_complete_slide), and are also divided by lecture below. Additional supporting material can be obtained on [Prof. Bertsekas' web site](http://web.mit.edu/dimitrib/www/publ.html).

**Note To OCW Users**: All videos are from [Shuvomoy Das Gupta](https://www.youtube.com/playlist?list=PLiCLbsFQNFAxOmVeqPhI5er1LGf2-L9I4) on Youtube and are not provided under our [Creative Commons License](/terms/#cc).

| TOPICS | VIDEO LECTURES | LECTURE NOTES |
| --- | --- | --- |
|  {{< br >}}{{< br >}} Introduction to Dynamic Programming (DP) {{< br >}}{{< br >}} *   Approximate DP{{< br >}}*   Finite Horizon Problems{{< br >}}*   DP Algorithm for Finite Horizon Problems{{< br >}}*   Infinite Horizon Problems{{< br >}}*   Basic Theory of Discounted Infinite Horizon Problems {{< br >}}{{< br >}}  |  {{< br >}}{{< br >}} [Approximate Dynamic Programming, Lecture 1, Part 1]({{< baseurl >}}/sections/related-video-lectures/approximate-dynamic-programming-lecture-1-part-1) {{< br >}}{{< br >}}  | [Lecture 1 (PDF)]({{< baseurl >}}/sections/related-video-lectures/mit6_231f15_lec1) |
| [Approximate Dynamic Programming, Lecture 1, Part 2]({{< baseurl >}}/sections/related-video-lectures/approximate-dynamic-programming-lecture-1-part-2) |
| [Approximate Dynamic Programming, Lecture 1, Part 3]({{< baseurl >}}/sections/related-video-lectures/approximate-dynamic-programming-lecture-1-part-3) |
|  {{< br >}}{{< br >}} Review of Discounted Problem Theory, Shorthand Notation {{< br >}}{{< br >}} *   Algorithms for Discounted DP{{< br >}}*   Value Iteration (VI){{< br >}}*   Policy Iteration (PI){{< br >}}*   Q-Factors and Q-Learning{{< br >}}*   DP Models{{< br >}}*   Asynchronous Algorithms {{< br >}}{{< br >}}  | [Approximate Dynamic Programming, Lecture 2, Part 1]({{< baseurl >}}/sections/related-video-lectures/approximate-dynamic-programming-lecture-2-part-1) | [Lecture 2 (PDF)]({{< baseurl >}}/sections/related-video-lectures/mit6_231f15_lec2) |
| [Approximate Dynamic Programming, Lecture 2, Part 2]({{< baseurl >}}/sections/related-video-lectures/approximate-dynamic-programming-lecture-2-part-2) |
| [Approximate Dynamic Programming, Lecture 2, Part 3]({{< baseurl >}}/sections/related-video-lectures/approximate-dynamic-programming-lecture-2-part-3) |
|  {{< br >}}{{< br >}} General Issues of Approximation and Simulation for Large-Scale Problems {{< br >}}{{< br >}} *   Introduction to Approximate DP{{< br >}}*   Approximation Architectures{{< br >}}*   Simulation-Based Approximate Policy Evaluation{{< br >}}*   General Issues Regarding Approximation and Simulation {{< br >}}{{< br >}}  | [Approximate Dynamic Programming, Lecture 3, Part 1]({{< baseurl >}}/sections/related-video-lectures/approximate-dynamic-programming-lecture-3-part-1) | [Lecture 3 (PDF)]({{< baseurl >}}/sections/related-video-lectures/mit6_231f15_lec3) |
| [Approximate Dynamic Programming, Lecture 3, Part 2]({{< baseurl >}}/sections/related-video-lectures/approximate-dynamic-programming-lecture-3-part-2) |
|  {{< br >}}{{< br >}} Approximate Policy Iteration based on Temporal Differences, Projected Equations, Galerkin Approximation {{< br >}}{{< br >}} *   Approximation in Value Space{{< br >}}*   Approximate VI and PI{{< br >}}*   Projected Bellman Equations{{< br >}}*   Matrix Form of the Projected Equation{{< br >}}*   Simulation-Based Implementation{{< br >}}*   LSTD and LSPE Methods{{< br >}}*   Bias-Variance Tradeoff {{< br >}}{{< br >}}  | [Approximate Dynamic Programming, Lecture 4, Part 1]({{< baseurl >}}/sections/related-video-lectures/approximate-dynamic-programming-lecture-4-part-1) | [Lecture 4 (PDF)]({{< baseurl >}}/sections/related-video-lectures/mit6_231f15_lec4) |
| [Approximate Dynamic Programming, Lecture 4, Part 2]({{< baseurl >}}/sections/related-video-lectures/approximate-dynamic-programming-lecture-4-part-2) |
|  {{< br >}}{{< br >}} Aggregation Methods {{< br >}}{{< br >}} *   Review of Approximate PI Based on Projected Bellman Equations{{< br >}}*   Issues of Policy Improvement{{< br >}}*   Exploration Enhancement in Policy Evaluation{{< br >}}*   Oscillations in Approximate PI{{< br >}}*   Aggregation: Examples, Simulation-Based, Relation with Projected Equations {{< br >}}{{< br >}}  | [Approximate Dynamic Programming, Lecture 5, Part 1]({{< baseurl >}}/sections/related-video-lectures/approximate-dynamic-programming-lecture-5-part-1) | [Lecture 5 (PDF)]({{< baseurl >}}/sections/related-video-lectures/mit6_231f15_lec5) |
| [Approximate Dynamic Programming, Lecture 5, Part 2]({{< baseurl >}}/sections/related-video-lectures/approximate-dynamic-programming-lecture-5-part-2) |
| [Approximate Dynamic Programming, Lecture 5, Part 3]({{< baseurl >}}/sections/related-video-lectures/approximate-dynamic-programming-lecture-5-part-3) |
|  {{< br >}}{{< br >}} Q-Learning, Approximation in Policy Space {{< br >}}{{< br >}} *   Review of Q-Factors and Bellman Equations for Q-Factors{{< br >}}*   VI and PI for Q-Factors{{< br >}}*   Q-Learning: Combination of VI and Sampling{{< br >}}*   Q-Learning and Cost Function Approximation{{< br >}}*   Adaptive Dynamic Programming{{< br >}}*   Approximation in Policy Space{{< br >}}*   Additional Topics {{< br >}}{{< br >}}  | [Approximate Dynamic Programming, Lecture 6, Part 1]({{< baseurl >}}/sections/related-video-lectures/approximate-dynamic-programming-lecture-6-part-1) | [Lecture 6 (PDF)]({{< baseurl >}}/sections/related-video-lectures/mit6_231f15_lec6) |
| [Approximate Dynamic Programming, Lecture 6, Part 2]({{< baseurl >}}/sections/related-video-lectures/approximate-dynamic-programming-lecture-6-part-2) 

**{{< anchor "2012" >}}{{< /anchor >}}Summer 2012**
---------------------------------------------------

These notes are from a condensed, more research-oriented version of the course, given by Prof. Bertsekas in Summer 2012.

[Short Course Notes (PDF)]({{< baseurl >}}/sections/related-video-lectures/mit6_231f15_notes_short)

| LEC # | LECTURE NOTES |
| --- | --- |
| 1 | [Exact DP: Infinite Horizon Problems (PDF)]({{< baseurl >}}/sections/related-video-lectures/mit6_231f15_lec01_short) |
| 2 | [Exact DP: Large-scale Computational Methods (PDF)]({{< baseurl >}}/sections/related-video-lectures/mit6_231f15_lec02_short) |
| 3 | [General Issues of Approximation and Simulation (PDF)]({{< baseurl >}}/sections/related-video-lectures/mit6_231f15_lec03_short) |
| 4 | [Temporal Differences (TD), Projected Equations, Galerkin Approximation (PDF)]({{< baseurl >}}/sections/related-video-lectures/mit6_231f15_lec04_short) |
| 5 | [Aggregation Methods (PDF)]({{< baseurl >}}/sections/related-video-lectures/mit6_231f15_lec05_short) |
| 6 | [Stochastic Approximation, Q-learning, and Other Methods (PDF)]({{< baseurl >}}/sections/related-video-lectures/mit6_231f15_lec06_short) |
| 7 | [Monte Carlo Methods (PDF)]({{< baseurl >}}/sections/related-video-lectures/mit6_231f15_lec07_short)